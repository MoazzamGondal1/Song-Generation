{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from datetime import datetime\n",
    "\n",
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  \n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "def create_lyrics_corpus(dataset, field):\n",
    "  # Remove all other punctuation\n",
    "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "  # Make it lowercase\n",
    "  dataset[field] = dataset[field].str.lower()\n",
    "  # Make it one long string to split by line\n",
    "  lyrics = dataset[field].str.cat()\n",
    "  corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "  for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "  corpus = [l for l in corpus if l != '']\n",
    "\n",
    "  return corpus\n",
    "\n",
    "def get_time():\n",
    "  # Get the current date and time\n",
    "  current_datetime = datetime.now()\n",
    "\n",
    "  formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H%M\")\n",
    "\n",
    "  return formatted_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting 100 hip hop songs randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist\n",
       "Travis-Scott      28\n",
       "Kendrick-Lamar    21\n",
       "Eminem            17\n",
       "J-Cole            16\n",
       "Snoop-Dogg        16\n",
       "Maroon-5           1\n",
       "Ed-Sheeran         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_songs = pd.read_csv(\"SongsData_hiphop.csv\")\n",
    "random_songs_df = all_songs.sample(n=100, random_state=42)\n",
    "random_songs_df['Artist'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokeniziation and BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2934\n"
     ]
    }
   ],
   "source": [
    "corpus = create_lyrics_corpus(random_songs_df,\"Lyrics\")\n",
    "tokenizer = tokenize_corpus(corpus)\n",
    "total_words = len(tokenizer.word_index)+1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Sequences to fit in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tsequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_pad_len = max([len(seq) for seq in sequences])\n",
    "print(max_pad_len)\n",
    "padded_sequences = np.array(pad_sequences(sequences,maxlen=max_pad_len,truncating='post'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "input_sequences, labels = padded_sequences[:,:-1], padded_sequences[:,-1]\n",
    "\n",
    "# One-hot encode the labels\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "486/486 [==============================] - 57s 106ms/step - loss: 6.4675 - accuracy: 0.0643\n",
      "Epoch 2/20\n",
      "486/486 [==============================] - 46s 95ms/step - loss: 5.3130 - accuracy: 0.1412\n",
      "Epoch 3/20\n",
      "486/486 [==============================] - 41s 83ms/step - loss: 4.7552 - accuracy: 0.2034\n",
      "Epoch 4/20\n",
      "486/486 [==============================] - 41s 84ms/step - loss: 3.9692 - accuracy: 0.2625\n",
      "Epoch 5/20\n",
      "486/486 [==============================] - 41s 84ms/step - loss: 3.1395 - accuracy: 0.3459\n",
      "Epoch 6/20\n",
      "486/486 [==============================] - 42s 86ms/step - loss: 2.5858 - accuracy: 0.4213\n",
      "Epoch 7/20\n",
      "486/486 [==============================] - 43s 88ms/step - loss: 2.2322 - accuracy: 0.4854\n",
      "Epoch 8/20\n",
      "486/486 [==============================] - 42s 87ms/step - loss: 1.9952 - accuracy: 0.5218\n",
      "Epoch 9/20\n",
      "486/486 [==============================] - 43s 89ms/step - loss: 1.8958 - accuracy: 0.5455\n",
      "Epoch 10/20\n",
      "486/486 [==============================] - 42s 86ms/step - loss: 1.9314 - accuracy: 0.5373\n",
      "Epoch 11/20\n",
      "486/486 [==============================] - 43s 88ms/step - loss: 1.7267 - accuracy: 0.5810\n",
      "Epoch 12/20\n",
      "486/486 [==============================] - 42s 87ms/step - loss: 1.6369 - accuracy: 0.5982\n",
      "Epoch 13/20\n",
      "486/486 [==============================] - 43s 88ms/step - loss: 1.4872 - accuracy: 0.6282\n",
      "Epoch 14/20\n",
      "486/486 [==============================] - 43s 88ms/step - loss: 1.4161 - accuracy: 0.6459\n",
      "Epoch 15/20\n",
      "486/486 [==============================] - 42s 86ms/step - loss: 1.4366 - accuracy: 0.6414\n",
      "Epoch 16/20\n",
      "486/486 [==============================] - 43s 88ms/step - loss: 1.3985 - accuracy: 0.6568\n",
      "Epoch 17/20\n",
      "486/486 [==============================] - 43s 89ms/step - loss: 1.4007 - accuracy: 0.6535\n",
      "Epoch 18/20\n",
      "486/486 [==============================] - 45s 93ms/step - loss: 1.3955 - accuracy: 0.6525\n",
      "Epoch 19/20\n",
      "486/486 [==============================] - 45s 92ms/step - loss: 1.3979 - accuracy: 0.6554\n",
      "Epoch 20/20\n",
      "486/486 [==============================] - 45s 93ms/step - loss: 1.3473 - accuracy: 0.6624\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 256, input_length=max_pad_len-1))\n",
    "#model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model = load_model(\"hiphop_model_x1_2023-12-03_2322.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486/486 [==============================] - 95s 186ms/step - loss: 3.4365 - accuracy: 0.3015\n"
     ]
    }
   ],
   "source": [
    "history = reload_model.fit(input_sequences, one_hot_labels, epochs = 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiphop_model_x2_2023-12-03_2337.h5\n"
     ]
    }
   ],
   "source": [
    "model_name = \"hiphop_model_x2_\" + get_time() + \".h5\"\n",
    "reload_model.save(model_name)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6778765916824341\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history['accuracy']\n",
    "print(accuracy[-1])\n",
    "# Plotting accuracy over epochs\n",
    "# plt.plot(range(1, len(accuracy) + 1), accuracy)\n",
    "# plt.title('Training Accuracy Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "just do it hoodie eve hoodie hoodie hoodie hoodie hotel hoodie hoodie hotel hotel hotel hotel hotel hotel turn hotel day hotel turn myself lookin' shoot dreams from turn touched from day slummin' touched room'll rock hard mode holding it fuckin' philosophyme woo herself bomb realize four roof sexy indiscretions yeahcome hounds one\n"
     ]
    }
   ],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"just do it\"\n",
    "next_words = 50\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_pad_len-1, padding='post')\n",
    "  predicted_probs = reload_model.predict(token_list)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
